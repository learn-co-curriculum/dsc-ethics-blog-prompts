# Data Science Ethics Blog Prompts
A collection of prompts for blog posts about data science ethics created for Flatiron students.

## Data Privacy and Security

1. Aside from overtly illegal practices according to current legislation, data privacy and ethics calls into question a myriad of various thought experiments. For example:
	* Should IP addresses or cookies be considered PII?
	* How should security camera footage be handled? 
	* What about vehicles such as Google street view cars which are capturing video and pictures of public places? 
Discuss your thoughts about:
  * Should organizations be allowed to maintain massive databases of said information? 
  * What regulations should be put on these and other potentially sensitive datasets?

2. Various legislation like GDPR has been introduced to manage user privacy and security in the data space. However, there is also an impetus on companies and users to take some accountability for the privacy and security of user data. Who do you think has the most power and/or responsibility to protect user data -- the government, companies, or users?

3. In GDPR, the standard for data collection is defined as "on a lawful basis". This includes:
  1. consent from the subject
  2. to fulfill a contractual obligation entered into by the subject
  3. to comply with the data collectors legal obligations
  4. to protect the data subjects vital interests
  5. for the public interest
  6. to pursue the legitimate interests of the data controller
  Do you think that the justifications for data collection listed above are sufficient to protect users? Why or why not?


## Sensitive Features
1. Logistic regression and other algorithms are used to inform a wide range of decisions including:
	1. whether to provide someone with a loan
	2. the degree of criminal sentencing
	3. whether to hire an individual for a job. 
Choose one of the decisions listed above and discuss how historical bias might impact the underlying data and how this can impact the fairness of the model.


2. The Boston Housing dataset contains a number of features that can be considered sensitive in isolation but can be especially problematic when combined. Select a combination of features might produced an analysis that is plagued by either measurement bias or algorithmic bias. Describe how the combination of features might lead to a biased analysis.


## Machine Learning Bias
1. In the past, systems like the one used at St. George's Hospital Medical School in the early 1980s that docked applicants 3 points for being female and 15 points for being non-European applied bias to the algorithms they implemented. Research and summarize another case where blatant bias about a sample population was built into an algorithm and discuss how the disparate treatment caused a disparate impact on the effected sample population.
